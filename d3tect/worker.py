from collections import Counter
from operator import attrgetter
from logging import getLogger, debug, info, warn, error, DEBUG, INFO
from sys import exit

from tabulate import tabulate
from d3tect.tidata import TIData
from d3tect.model import Datasource, Technique, fresh_links
from d3tect.helper import _read_yaml_file
from collections import OrderedDict
import re
import copy
import rbo
from scipy import stats
import statistics


class worker:
    # dict to count instances of tactics
    default_t_filter = {
        'max_techniques': 0,
        'techniques_tactic': [],
        'ranking_type': Technique.ranks_t[0]
    }

    no_ds_key = 'NO_DATASOURCE'  # this is defined in the yaml file generated by attack-stix

    def __init__(self):
        # self.total_tactics = Counter()
        self.total_sw = Counter()
        self.total_grp = Counter()
        self.ds_dict = None  # datasource dict
        ##self.t_list = [] # technique list
        self.t_dict = None  # technique dict, holds copys of technique dict
        self.tactic_set = set()
        self.tactic_dict = {}
        # self.datasources = None # datasources (header) from csv
        # self.infos = None # elements (header) from csv
        self.t_filter = self.default_t_filter
        self.apply_t_filter = False
        self.fname_with_tactis = False
        self.fname_shorten = False
        self.include_subt = True
        self.detection_levels = []

    def _set_debug(self, level=DEBUG):
        getLogger().setLevel(level)

    def read_yml_fill_dicts(self, filename, merged=False, include_subt=True, filter=None):
        db_tmp = _read_yaml_file(filename)
        self.include_subt = include_subt

        debug(f"Reading {filename}\n"
              f"Number of techniques: {len(db_tmp['technique'])}\n"
              f"Number of main-techniques: {len([t for t in db_tmp['technique'] if db_tmp['technique'][t]['is_subtechnique'] == False])}\n"
              f"Number of sub-techniques: {len([t for t in db_tmp['technique'] if db_tmp['technique'][t]['is_subtechnique']])}\n"
              f"Number of datasource: {len(db_tmp['datasource'])}\n"
              f"Number of software examples: {len(db_tmp['software'])}\n"
              f"Number of group examples: {len(db_tmp['group'])}\n")

        if (merged):
            db_tmp = worker.merge_prim_subtechnique(db_tmp, include_subt)

        # build dicts for local worker object, get infos from database
        self.ds_dict = worker.build_ds_dict_from_db(db_tmp)
        self.t_dict = worker.build_t_dict_from_db(db_tmp)

        # create vanilla ds_dict t_dict these are not linked yet
        self.vanilla_ds_dict = copy.deepcopy(self.ds_dict)
        self.vanilla_t_dict = copy.deepcopy(self.t_dict)

        # build sets for statistics and to calc weight
        self.build_sets()
        worker.set_grp_weight_on_dict(self.t_dict, worker.calc_grp_weight(self.total_sw, self.total_grp))

        debug(f'finished building technique dict {self.t_dict}')

        # link datasources with techniques and vice versa
        fresh_links(self.ds_dict, self.t_dict)

        Technique.get_n_calc_metric(self.t_dict)
        Technique.do_ranking(self.t_dict)
        Datasource.calc_metrics(self.ds_dict, self.t_dict)
        Datasource.do_ranking(self.ds_dict)

        # cosmetics for prints
        self.build_fnames()

    @staticmethod
    def build_ds_dict_from_db(db_tmp):
        return dict((dk, Datasource(dk)) for dk in db_tmp['datasource'].keys() if
                    dk not in worker.no_ds_key)  # remove NO_DATASOURCE FROM DICT

    @staticmethod
    def build_ds_dict_from_listofobjects(listofobjects):
        return dict((dk.name, dk) for dk in listofobjects)

    # t_dict holds object copies of db object
    @staticmethod
    def build_t_dict_from_db(db_tmp):
        return dict((t['id'], Technique(t.copy())) for t in db_tmp['technique'].values())

    """build sets from t_dict only possible with mitre dataset"""

    def build_sets(self):
        for t in self.t_dict.values():
            self.total_sw.update(t.technique['sw_examples'])
            self.total_grp.update(t.technique['grp_examples'])
            self.tactic_set.update(t.technique['tactic'])

        info("No of software examples: " + str(len(self.total_sw)))
        info("No of group examples: " + str(len(self.total_grp)))
        info("no of tactics: " + str(len(self.tactic_set)))
        for t in self.tactic_set:
            debug(t)
            self.tactic_dict[t] = 0
        info("\n\n")

    """requires sets to be built first only possible with mitre dataset"""

    @staticmethod
    def calc_grp_weight(total_sw, total_grp):
        total_sw = len(total_sw)
        total_grp = len(total_grp)
        if (total_sw == 0 or total_grp == 0):
            raise Exception("Either grp or sw examples is 0, that is impossible")

        grp_weight = round(total_sw / total_grp, 2)  # *2.5
        info("Group weight is: " + str(grp_weight))
        return grp_weight

    @staticmethod
    def set_grp_weight_on_dict(dict, weight):
        for item in dict.values():
            item.grp_weight = weight

    @staticmethod
    def merge_prim_subtechnique(db_tmp, include_subt) -> None:
        techniques = db_tmp['technique']
        r_t = re.compile('^T\d{4}$')
        r_st = re.compile('^T\d{4}.\d{3}$')
        t_dict = dict()

        for obj in techniques.values():
            if r_t.match(obj['id']):
                obj = copy.deepcopy(obj)
                t_dict[obj['id']] = obj
                obj['techniques_merged'] = 0

                debug(f"Main technique prepared for merge: {obj['id']}")

        for obj in techniques.values():
            if r_st.match(obj['id']):
                st_of_id = obj['id'].split('.')[0]
                worker.t_merge(t_dict[st_of_id], obj)
                if include_subt:
                    obj = copy.deepcopy(obj)
                    t_dict[obj['id']] = obj

        db_tmp['technique'] = t_dict
        return db_tmp

    @staticmethod
    def t_merge(t, st) -> None:
        debug(f"Merging {st['id']} into {t['id']}")

        t['techniques_merged'] += 1
        t['datasources'].extend(x for x in st['datasources'] if x not in t['datasources'])
        t['tactic'].extend(x for x in st['tactic'] if x not in t['tactic'])
        # t['platforms'].extend(x for x in st.platforms if x not in t.platforms)
        # t.permissions_required.extend(x for x in st.permissions_required if x not in t.permissions_required)

        # t.last_mod = "" # TODO
        # t.created = "" # TODO
        t['grp_examples'].extend(x for x in st['grp_examples'] if x not in t['grp_examples'])
        t['sw_examples'].extend(x for x in st['sw_examples'] if x not in t['sw_examples'])

        # t.references.extend(x for x in st.references if x not in t.references) #PATCHED version with stripped ids

        # t_rev_wo_ids = [re.sub('^\d{1,3}: ', '', x) for x in t.references]
        # st_rev_wo_ids = [re.sub('^\d{1,3}: ', '', x) for x in st.references]
        # t.references = t_rev_wo_ids + [x for x in st_rev_wo_ids if x not in t_rev_wo_ids]

        t['no_examples_sw'] = len(t['sw_examples'])
        t['no_examples_grp'] = len(t['grp_examples'])
        t['no_examples'] = t['no_examples_sw'] + t['no_examples_grp']
        # t['no_references'] = len(t['references'])

    # TODO this should be moved to get_name or something within the respective technique / datasource class
    def build_fnames(self):
        for t in self.t_dict.values():
            t.no_of_tactics = len(t.tactics)
            name = t.name.split(':')
            if (len(name) > 1) and self.fname_shorten:
                name[0] = "".join(filter(str.isupper, name[0]))
            name = ': '.join(name)
            t.fname = f'{name}'
            # if(self.fname_with_tactis):
            #    t.fname = '{} ({}/{})'.format(t.fname, t.metric['no_tactics'], len(self.tactic_dict))
        for ds in self.ds_dict.values():
            ds.fname = ds.name
            if (self.fname_with_tactis):
                ds.fname = '{} ({}/{})'.format(ds.fname, ds.metric['total_no_tactics'], len(self.tactic_dict))

    def print_general_stats(self):
        print(f"Reading \n"
              f"Number of techniques: {len(self.t_dict.values())}\n"
              f"Number of main-techniques: {len([t for t in self.t_dict.values() if t.technique['is_subtechnique'] == False])}\n"
              f"Number of sub-techniques: {len([t for t in self.t_dict.values() if t.technique['is_subtechnique']])}\n"
              f"Number of datasource: {len(self.ds_dict.values())}\n"
              f"Number of software examples: {len(self.total_sw)}\n"
              f"Number of group examples: {len(self.total_grp)}\n")

    def print_techniques_without_ds(self):
        print('\n\nTechniques without datasources: ')
        t_without_ds = []
        for t in self.t_dict.values():
            if len(t.datasources) == 0:
                t_without_ds.append(t)

        # sort tactics to make it readable
        for tactic in self.tactic_set:
            tmp_t_without_ds = []
            for t in t_without_ds:
                if tactic in t.tactics:
                    tmp_t_without_ds.append(t)
                    print('{:<30} Examples: {} Name: {} ({})'.format('; '.join(t.tactics), t.metric['no_examples'],
                                                                     t.name, t.id))
            if len(tmp_t_without_ds) > 0:
                print('Total of tactic {}: {}\n'.format(tactic, ', '.join([t.id for t in tmp_t_without_ds])))

        print('\n=====\nSUM Total: ' + ', '.join([t.id for t in t_without_ds]))

    def print_rank_comparision_techniques_tidata_diff(self, print_only_generic_stats=False, print_list=True,
                                                      print_missing=False, sort_type='rank_total_no_examples_grp',
                                                      path='../DeTTECT/threat-actor-data/pre-sub-techniques/', top=1000,
                                                      latex=False, compared_ranks=[], with_val=False, with_names=True,
                                                      tablefmt="plain"):
        tidata = TIData()
        db_dict = tidata._get_technique_ranking_from_database(path=path, include_subt=self.include_subt)
        tab = []  # tabular
        full_t_list_sorted = []
        x1, x2 = [], {}
        rank = 0

        for t in sorted(self.t_dict.values(), key=lambda x: x.get_rank_by_name(sort_type), reverse=False):
            full_t_list_sorted.append(t.id)

        for t in sorted(self.t_dict.values(), key=lambda x: x.get_rank_by_name(sort_type), reverse=False):
            top -= 1

            if top < 0:
                break

            list_of_dbs_for_tech = tidata._get_technique_rank_from_database(t.id)

            # x1.append(t.get_rank_by_name(sort_type))

            new_line = [t.id]
            for db in tidata.dbs:
                if db in list_of_dbs_for_tech:
                    new_line.append(str(list_of_dbs_for_tech[db]))
                    # x2[db].append(list_of_dbs_for_tech[db])
                else:
                    new_line.append('')

            tab.append(new_line)

        # print(x2)

        t_tab = list(map(list, zip(*tab)))  # transposed tab to get infos for ti db
        list_of_t = t_tab.pop(0)  # remove first line (techniques) as we do not need this info, save for later

        tab.insert(0, ['id'] + list(range(1, tidata.no_dbs + 1)))  # append header for priting

        if (print_list == True):
            print(tabulate(tab, tablefmt=tablefmt))

        db_id = 1
        if (print_only_generic_stats == True):
            results = []
            for db in tidata.dbs:
                max_occurance, index = 0, 0
                t_list = full_t_list_sorted.copy()
                comp_list = [t[0] for t in db_dict[db_id - 1]['sorted_techniques']]
                max_loop = len(t_list)

                missing_t = [t for t in comp_list if t not in t_list]
                while (index < max_loop):
                    # debug(f"{db} {index}/{max_loop} {max_occurance}/{db_dict[db_id - 1]['no_techniques']}")
                    if t_list.pop(0) in comp_list:
                        max_occurance += 1
                    if max_occurance / db_dict[db_id - 1]['no_techniques'] == 1:
                        print(f"{index} \t {db}({db_id}) to detect all {db_dict[db_id - 1]['no_techniques']}t")
                        results.append(index)
                        break
                    index += 1
                if (index == max_loop):
                    if (len(missing_t)):
                        print(
                            f"Miss \t {db}({db_id}) to detect all {db_dict[db_id - 1]['no_techniques']}t. Missing {len(missing_t)}t: {missing_t}")
                    else:
                        print(f"Max \t {db}({db_id}) to detect all {db_dict[db_id - 1]['no_techniques']}t")
                db_id += 1
            print(
                f"max {max(results)}, min {min(results)}, median {statistics.median(results)}, mean {round(statistics.mean(results), 2)}")
            return

        for db in tidata.dbs:
            occurance = 0  # holds occurance of techniques in result
            oc_top = {10: 0, 20: 0, 40: 0, 50: 0, 100: 0}  # like occurance but with top10, 20, eg; can be extended
            for e in t_tab[db_id - 1]:
                if e:
                    occurance += 1
                    if e.isnumeric():
                        e = int(e)
                        for top in oc_top.keys():
                            if e <= top: oc_top[top] += 1
            marker = ''
            if (occurance / db_dict[db_id - 1]['no_techniques']) == 1:
                marker = '|'
            print(f"{marker}{db_id} {db} {occurance}/{db_dict[db_id - 1]['no_techniques']}")
            if sum(oc_top.values()) > 0:
                print(f"Stats Top x Techniques {oc_top}")
            if print_missing:
                missing_list = tidata._get_missing_techniques_for_db(list_of_t, db_id - 1)
                if len(missing_list):
                    print("Missing Techniques:")
                    if missing_list[0][1] == 'x':
                        new_missing = []
                        for x in missing_list:
                            try:
                                name = self.t_dict[x[0]].name
                                if with_names:
                                    print(f'{x[0]} ({name})')
                                else:
                                    new_missing.append(x[0])
                            except KeyError as e:
                                print(f'\t{x[0]} does not exist in db.')
                        print(', '.join(new_missing))
                    else:
                        missing_list2 = []
                        for item in missing_list:
                            try:
                                item.extend(
                                    [self.get_t_info(self.t_dict[item[0]], x, with_val=True) for x in compared_ranks])
                                if with_names: item.append(self.t_dict[item[0]].name)
                                missing_list2.append(item)
                            except KeyError as e:
                                print(f'{item[0]} does not exist in db.')

                        header = ['ID', 'Rank', 'Val']
                        header.extend([Technique.rank_header[x] for x in compared_ranks])
                        missing_list2.insert(0, header)
                        print(tabulate(missing_list2, tablefmt=tablefmt))
                    print('')
            db_id += 1

    def get_t_info(self, t, index, with_val=False):
        t_rank = t.get_rank(index)
        t_value = t.get_metric(index)
        if (with_val):
            return (f'{t_rank}: {t_value}')
        return (t_rank)

    def get_t_info_diff(self, t, index, diffindex, comp_rank=False, with_val=False):
        r1 = self.get_t_info(t, index)
        r2 = self.get_t_info(t, diffindex)
        diff = r2 - r1
        rrc = worker.calc_rrc(r1, r2)
        if (with_val):
            r2 = self.get_t_info(t, diffindex, with_val=with_val)
        if (comp_rank):
            return (f'{r2} ({diff}, {rrc})')
        return (r2)

    def get_t_info_diff2(self, t, index, t2, index2, comp_rank=False, with_val=False):
        r1 = self.get_t_info(t, index)
        r2 = self.get_t_info(t2, index2)
        arc = r2 - r1
        rrc = worker.calc_rrc(r1, r2)
        if (with_val):
            r2 = self.get_t_info(t2, index2, with_val=with_val)
        if (comp_rank):
            return (f'{r2} ({arc}, {rrc})')
        return (r2)

    def print_rank_comp2(self, ref_dict, sort_type=1, top=10, tablefmt="plain", with_val=False, comp_rank=False,
                         compared_ranks=[], cd_dict=None, skip_tau=False):
        tab = []
        index = sort_type

        header = ['Name']
        objtype = next(iter(ref_dict.values())).__class__
        if (objtype == Technique): header.insert(0, 'ID')

        header.append(objtype.rank_header[index])
        for rank_db in compared_ranks:
            rank_db_name = rank_db[1]
            for rank in rank_db[2]:
                header.append("{}: {}".format(rank_db_name, objtype.rank_header[rank]))

        tab.append(header)

        ntop = top
        for t in sorted(ref_dict.values(), key=lambda x: x.get_rank(sort_type), reverse=False):
            if not ntop:
                break
            if not t.fname:
                t.fname = t.name
            new_line = [t.fname]
            if (objtype == Technique): new_line.insert(0, t.id)
            new_line.append(self.get_t_info(t, index, with_val=with_val))
            for rank_db in compared_ranks:
                for rank in rank_db[2]:
                    try:
                        new_line.append(self.get_t_info_diff2(t, index, rank_db[0][t.id], rank, comp_rank=comp_rank,
                                                              with_val=with_val))
                    except KeyError:
                        new_line.append('')

            tab.append(new_line)
            ntop -= 1

        spacer = [""]
        if (objtype == Technique): spacer = ["", ""]
        stats_top = worker.get_ranking_comp2(ref_dict, sort_type=sort_type, compared_ranks=compared_ranks, top=top,
                                             skip_tau=skip_tau)
        stats_total = worker.get_ranking_comp2(ref_dict, sort_type=sort_type, compared_ranks=compared_ranks, top=0,
                                               skip_tau=skip_tau)
        tab.append(["RBO Total"] + spacer + stats_total['rbo'])
        tab.append(["RBO Top {}".format(top)] + spacer + stats_top['rbo'])
        tab.append(["Kendall TAU Total"] + spacer + stats_total['kendalltau'])
        tab.append(["Kendall Top {}".format(top)] + spacer + stats_top['kendalltau'])
        # tab.append(worker.get_rankcomp_line("RBO Total", worker.calc_rbo, 0, type, ref_dict, sort_type, compared_ranks))
        # tab.append(worker.get_rankcomp_line("Kendall Tau Total", worker.calc_kendalltau, 0, type, ref_dict, sort_type, compared_ranks))
        # tab.append(worker.get_rankcomp_line("RBO Top {}".format(top), worker.calc_rbo, top, type, ref_dict, sort_type, compared_ranks))
        # tab.append(worker.get_rankcomp_line("Kendall Top {}".format(top), worker.calc_kendalltau, top, type, ref_dict, sort_type, compared_ranks))

        print(tabulate(tab, tablefmt=tablefmt))

    @staticmethod
    def print_rank_comp_path(path, comp_path=[], top=10, tablefmt="plain"):
        tab = []
        x1, x2, a, b = [], {}, [], {}

        header = ['DS Name', 'Rank']
        header += [p[0] for p in comp_path]

        tab.append(header)

        ntop = top
        counter = 0
        a = [ds for ds in path['ds']]
        for ds in path['ds']:
            counter += 1
            new_line = [ds, counter]
            x1.append(counter)

            for p in comp_path:
                my_p_name = p[0]
                my_p = p[1]
                my_counter = 0
                rank = 0
                for my_ds in my_p['ds']:  # expensive but cheap
                    my_counter += 1
                    if my_ds == ds:
                        rank = my_counter
                x2.setdefault(my_p_name, []).append(rank)  # expensive but cheap
                b[my_p_name] = [my_ds for my_ds in my_p['ds']]  # expensive but cheap
                new_line.append(f"{rank} ({(rank - counter)}, {worker.calc_rrc(counter, rank)})")
            #    new_line.append('')

            if (not top or ntop > 0):
                tab.append(new_line)
            ntop -= 1

        tab.append(["PATH LENGTH", len(path['ds'])] + [len(p[1]['ds']) for p in comp_path])
        tab.append(["PATH MISSING", len(path['missing'])] + [len(p[1]['missing']) for p in comp_path])

        tab.append(["TOTAL TAU", ""] + [worker.calc_kendalltau(x1, _x2) for _x2 in x2.values()])
        tab.append(["TOTAL RBO", ""] + [worker.calc_rbo(a, _b) for _b in b.values()])
        if (top):
            tab.append([f"TOP {top} TAU", ""] + [worker.calc_kendalltau(x1[:top], _x2[:top]) for _x2 in x2.values()])
            tab.append([f"TOP {top} RBO", ""] + [worker.calc_rbo(a[:top], _b[:top]) for _b in b.values()])
        print(tabulate(tab, tablefmt=tablefmt))

    def print_rank_comp(self, type='t', sort_type=1, top=10, tablefmt="plain", with_val=False, comp_rank=False,
                        compared_ranks=[], cd_dict=None):
        tab = []
        index = sort_type
        ref_dict = self.t_dict
        if type == 't':
            type = Technique
        elif type == 'cd':
            type = Datasource
            ref_dict = cd_dict
        elif type == 'ct':
            type = Technique
            ref_dict = cd_dict
        else:
            type = Datasource
            ref_dict = self.ds_dict
        """
        if type==Technique:
            for t in ref_dict.values():
                print(f"{t.id} {t.name} {t.datasources} {t.get_metric(3)}")
        """
        header = ['Name']
        if (type == Technique): header.insert(0, 'ID')
        header.append(type.rank_header[index])
        for rank in compared_ranks:
            header.append(type.rank_header[rank])

        tab.append(header)

        ntop = top
        for t in sorted(ref_dict.values(), key=lambda x: x.get_rank(sort_type), reverse=False):
            if not ntop:
                break
            if not t.fname:
                t.fname = t.name
            new_line = [t.fname]
            if (type == Technique): new_line.insert(0, t.id)
            new_line.append(self.get_t_info(t, index, with_val=with_val))
            for rank in compared_ranks:
                new_line.append(self.get_t_info_diff(t, index, rank, comp_rank=comp_rank, with_val=with_val))

            tab.append(new_line)
            ntop -= 1

        spacer = [""]
        if (type == Technique): spacer = ["", ""]
        stats_top = worker.get_ranking_comp2(ref_dict, sort_type=sort_type, compared_ranks=compared_ranks, top=top)
        stats_total = worker.get_ranking_comp2(ref_dict, sort_type=sort_type, compared_ranks=compared_ranks, top=0)
        tab.append(["RBO Total"] + spacer + stats_total['rbo'])
        tab.append(["RBO Top {}".format(top)] + spacer + stats_top['rbo'])
        tab.append(["Kendall TAU Total"] + spacer + stats_total['kendalltau'])
        tab.append(["Kendall Top {}".format(top)] + spacer + stats_top['kendalltau'])
        # tab.append(worker.get_rankcomp_line("RBO Total", worker.calc_rbo, 0, type, ref_dict, sort_type, compared_ranks))
        # tab.append(worker.get_rankcomp_line("Kendall Tau Total", worker.calc_kendalltau, 0, type, ref_dict, sort_type, compared_ranks))
        # tab.append(worker.get_rankcomp_line("RBO Top {}".format(top), worker.calc_rbo, top, type, ref_dict, sort_type, compared_ranks))
        # tab.append(worker.get_rankcomp_line("Kendall Top {}".format(top), worker.calc_kendalltau, top, type, ref_dict, sort_type, compared_ranks))

        print(tabulate(tab, tablefmt=tablefmt))

    @staticmethod
    def get_rank_with_ti_db(myworker, index, path='../DeTTECT/threat-actor-data/', include_subt=True):
        tidata = TIData()
        db_t_dict = tidata._get_technique_ranking_from_database(path=path, include_subt=include_subt)
        if index > len(db_t_dict):
            error(f"There are {len(db_t_dict)} dbs in {path}, you've requests db {index} ...")
            exit()

        new_ds_dict = copy.deepcopy(myworker.vanilla_ds_dict)
        new_t_dict = worker.convert_tidb_to_t_dict(myworker.vanilla_t_dict, db_t_dict[index])

        Technique.do_ranking(new_t_dict)

        fresh_links(new_ds_dict, new_t_dict)

        Datasource.calc_metrics(new_ds_dict, new_t_dict)
        Datasource.do_ranking(new_ds_dict)

        return {'cd': new_ds_dict, 'ct': new_t_dict, 'full_name': db_t_dict[index]['full_name']}



    @staticmethod
    def get_ranking_comp2(dict, sort_type=4, compared_ranks=[0, 4], top=0, skip_tau=False):
        x1, x2, a, b = [], {}, [], {}

        if not skip_tau:
            ntop = top
            for obj in sorted(dict.values(), key=lambda x: x.get_rank(sort_type), reverse=False):
                x1.append(obj.get_rank(sort_type))

                for rank_db in compared_ranks:
                    if (isinstance(rank_db, list)):
                        for rank in rank_db[2]:

                            try:
                                x2.setdefault(f"{rank_db[1]}{rank}", []).append(rank_db[0][obj.id].get_rank(rank))
                            except KeyError:
                                x2.setdefault(f"{rank_db[1]}{rank}", []).append(None)
                                skip_tau = True
                                break
                    else:
                        x2.setdefault(rank_db, []).append(dict[obj.id].get_rank(rank_db))
                ntop -= 1
                if (ntop == 0):
                    break

        if skip_tau:
            print("List elements are not even, skipping tau ...")
            tau = [None for x in compared_ranks]
        else:
            debug("TAU x1 {}: {}".format(len(x1), x1))
            for _ in x2.values():
                debug("TAU x2 {}: {}".format(len(_), _))
            tau = [worker.calc_kendalltau(x1, x) for x in x2.values()]

        for obj in sorted(dict.values(), key=lambda x: x.get_rank(sort_type), reverse=False):
            a.append(obj.id)

        if (top != 0):
            a = a[:top]

        for rank_db in compared_ranks:
            if (isinstance(rank_db, list)):
                ndict = rank_db[0]
                for rank in rank_db[2]:
                    for obj in sorted(ndict.values(), key=lambda x: x.get_rank(rank), reverse=False):
                        b.setdefault(f"{rank_db[1]}{rank}", []).append(obj.id)
            else:
                for obj in sorted(dict.values(), key=lambda x: x.get_rank(rank_db), reverse=False):
                    b.setdefault(rank_db, []).append(obj.id)

        debug("RBO a {}: {}".format(len(a), a))
        for _ in b.values():
            if (top != 0):
                _ = _[:top]
            debug("RBO b {}: {}".format(len(_), _))

        return {'kendalltau': tau,
                'rbo': [worker.calc_rbo(a, _b) for _b in b.values()],
                'dict_len': len(dict.values())}

    @staticmethod
    def convert_tidb_to_t_dict(vanilla_t_dict, db_t_dict):
        new_t_dict = {}
        for t in db_t_dict['sorted_techniques']:
            t_id = t[0]
            t_val = t[2]
            if t_id not in vanilla_t_dict.keys():
                warn(f"{t_id} unknown, skipping")
                continue
                # Exception("OH NO")
            new_t_dict[t_id] = copy.deepcopy(vanilla_t_dict[t_id])
            new_t_dict[t_id].clean_mitre_info()
            new_t_dict[t_id].custom_db_import = True
            if not t_val == '0' and not t_val == 'x':
                new_t_dict[t_id].metric['no_examples_weighted'] = t_val
            new_t_dict[t_id].metric['no_tactics'] = int(len(new_t_dict[t_id].technique['tactic']))


        return new_t_dict

    def print_rank_with_ti_db(self, index, path='../DeTTECT/threat-actor-data/', sort_type=4, compared_ranks=[],
                              ttype='cd', comp_rank=False, top=10):

        self.print_rank_comp(type=ttype, cd_dict=self.get_rank_with_ti_db(self, index - 1, path=path)[ttype],
                             sort_type=sort_type,
                             with_val=True, compared_ranks=compared_ranks, comp_rank=comp_rank, top=top)

    @staticmethod
    def get_shortest_path_for_detection(sort_type_ds=4, ref_ds_dict=None, ref_t_dict=None, excluded_ds=[],
                                        relink_t_in_detection=False):
        if not ref_ds_dict: raise Exception("ref_ds_dict required")
        if not ref_t_dict: raise Exception("ref_t_dict required")
        shortest_path = {}  # new dict with new copy of datsource objects
        finished = False

        n_ref_t_dict = {}
        for t in ref_t_dict.items():
            n_ref_t_dict[t[0]] = t[1]._mycopy_withval()
        ref_t_dict = n_ref_t_dict

        sorted_ds = sorted(ref_ds_dict.values(), key=lambda x: x.get_rank(sort_type_ds), reverse=False)
        while len(sorted_ds):  # while
            ds = sorted_ds.pop(0)  # take top

            if ds.name in excluded_ds:  # skip if ds
                info(f"excluded {ds.name}: {ds}")
                continue
            # if len(worker.get_detectable_techniques(ref_t_dict)) == 0:
            #    break
            ds_detects = False
            for t in ds.techniques:
                try:
                    t = ref_t_dict[t.id]
                except KeyError:
                    info(f"Missing {t.id} this should only the case when DS_DICT is more accurate than T_DICT")
                    continue
                if not t.detected:
                    ds_detects = True
                    t.detected = True
                    ds.techniques_in_detection.append(t)
            if ds_detects:
                info(f"\n\n\n{ds.name}\n")
                info(f"detections: {[t.id for t in ds.techniques_in_detection]}")

                shortest_path[ds.name] = ds._mycopy_withtid()
                ds.techniques_in_detection = []

                sorted_ds_dict = worker.build_ds_dict_from_listofobjects(sorted_ds)
                Datasource.calc_metrics(ds_dict=sorted_ds_dict, t_dict=ref_t_dict, ignore_detected=False)
                Datasource.do_ranking(sorted_ds_dict)  # do ranking, then use rank

                sorted_ds = sorted(sorted_ds_dict.values(), key=lambda x: x.get_rank(sort_type_ds), reverse=False)
                for ds in sorted_ds:
                    info(f"{ds.name} {ds.get_metric(sort_type_ds)}")

        # this stuff below could be circumvented, since we already have the results

        Datasource.calc_metrics(ds_dict=ref_ds_dict, t_dict=ref_t_dict)  # reset metrics
        Datasource.do_ranking(ds_dict=ref_ds_dict)  # and ranks out side the path

        # fresh_links(shortest_path, ref_t_dict)
        missing = worker.get_detectable_techniques(ref_t_dict)

        Datasource.calc_metrics_detection(shortest_path, ref_t_dict, reversable=relink_t_in_detection)
        Technique.rebuild_t_dict_from_ds_for_detection(shortest_path, ref_t_dict)
        Datasource.do_ranking(shortest_path)

        # and sorted
        shortest_path = OrderedDict(
            sorted(shortest_path.items(), key=lambda x: shortest_path[x[0]].get_rank(sort_type_ds), reverse=False))

        return ({'ds': shortest_path, 'missing': missing, 't': ref_t_dict})

    @staticmethod
    def get_detectable_techniques(ref_dict):
        # get list of all undetected techniques excluding "undetectable" (no datasources) techniques
        return [t.id for t in ref_dict.values() if len(t.technique['datasources']) > 0 and t.detected == False]

    @staticmethod
    def print_shortest_path_for_detection(sort_type_ds=4, ref_ds_dict=None, ref_t_dict=None, excluded_ds=[]):
        if not ref_ds_dict: raise Exception("ref_ds_dict required")
        if not ref_t_dict: raise Exception("ref_t_dict required")
        path = worker.get_shortest_path_for_detection(sort_type_ds=sort_type_ds, ref_ds_dict=ref_ds_dict,
                                                      ref_t_dict=ref_t_dict, excluded_ds=excluded_ds)


        print(f"Path length: {len(path['ds'])}\nExcluded DBs: {excluded_ds}")
        print([[ds.name, len(ds.techniques_in_detection), ds.get_metric(sort_type_ds), ds.get_rank(sort_type_ds),
                ref_ds_dict[ds.name].get_rank(sort_type_ds)] for ds in path['ds'].values()])
        if (path['missing']):
            missing = path['missing']
            print(f"{len(missing)} techniques are missing {missing}")

    @staticmethod
    def calc_t_ds_val(ds_dict, t_dict, ds_metric):
        for t in t_dict.values():  # clean list
            t.datasource_val = {}

        for val in Technique.ds_val_key:
            if val == 'max_ds_val':
                for t in t_dict.values():
                    t.datasource_val[val] = max([ds.get_metric(ds_metric) for ds in t.datasources], default=0)
            if val == 'min_ds_rank':
                for t in t_dict.values():
                    t.datasource_val[val] = min([ds.get_rank(ds_metric) for ds in t.datasources], default=0)

    @staticmethod
    def calc_rrc(pos1, pos2):
        return round((pos1 - pos2) / (pos1 + pos2), 2)

    """ Wrapper for Kendall Tau
    x1, x2 must be arrays of rankings in the same shape.
    x1 = [1,2,3]
    x2 = [3,2,1]
    """

    @staticmethod
    def calc_kendalltau(x1, x2):
        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.kendalltau.html
        # this should only work on lists with same elements
        # https://godatadriven.com/blog/using-kendalls-tau-to-compare-recommendations/
        # x1 = [1, 2, 3]
        # x2 = [3, 2, 1]

        if not all(isinstance(x, int) for x in x1 + x2):
            print("Sorry there are elements missing in the list. Try it the other way arround.")

        tau, p_value = stats.kendalltau(x1, x2)
        return round(tau, 2)

    """Wrapper for RBO
    x1,x2 must be ranked lists in a ranked order. Items can be alphanummeric and don't have
    to be in the same shape. No duplicates allowed.

    This functions a bit different than kendalltau so we have to make an order
    """

    @staticmethod
    def calc_rbo(a, b):
        # https://github.com/changyaochen/rbo
        # a = ['a', 'b', 'c']
        # b = ['a', 'c']

        return round(rbo.RankingSimilarity(a, b).rbo(), 2)